{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DrEyeBot Retinal Image Analysis using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import sys\n",
    "import imutils\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sn\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "from keras import applications\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.initializers import glorot_normal\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pyimagesearch.smallervggnet import SmallerVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13961969249502847968\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2672331157601856877\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levelset(x):\n",
    "    \"\"\" Sets Levels 1-4 to level 1\"\"\"\n",
    "    if x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def RMSE(actual, predict):\n",
    "    diff = actual - predict\n",
    "    diff = sum(diff**2) / len(actual)\n",
    "    return np.sqrt(diff)\n",
    "\n",
    "def select_toy_images(image_label,N=-1,images_percent=list()):\n",
    "    \"\"\" Selects number of images from each class. By default it is ALL images\"\"\"\n",
    "    image_list = list()\n",
    "    final_images = pd.DataFrame(columns = image_label.columns)\n",
    "    # We create a toy dataset of 'N' images, maintaining the split of the original \n",
    "    if N==-1:\n",
    "            # We need to pick all the images. No need to sample\n",
    "            # We can ignore the percentage here\n",
    "            final_images = image_label\n",
    "    else:\n",
    "        for level in range(5):\n",
    "        # Get respective number of images in each level\n",
    "            if len(images_percent)==5:\n",
    "                number_of_images = int(images_percent[level]*N/100)\n",
    "            else:\n",
    "                # We have no percentage of images. Setting the default safe percentage\n",
    "                images_percent = [73.6,6.9,15.1,2.4,2]\n",
    "                number_of_images = int(images_percent[level]*N/100)\n",
    "            sample_images = image_label[image_label.level==level].sample(n=number_of_images,axis=0)\n",
    "            frames = [final_images,sample_images]\n",
    "            final_images = pd.concat(frames).reset_index(drop=True)\n",
    "    return final_images \n",
    "\n",
    "def preprocess(image,scale=224):\n",
    "    \"\"\" preprocess the test image and covert to array \"\"\"\n",
    "    inter=cv2.INTER_AREA\n",
    "    (h, w) = image.shape[:2]\n",
    "    dW = 0\n",
    "    dH = 0\n",
    "\n",
    "    width = scale\n",
    "    height = scale\n",
    "\n",
    "    # if the width is smaller than the height, then resize\n",
    "    # along the width (i.e., the smaller dimension) and then\n",
    "    # update the deltas to crop the height to the desired\n",
    "    # dimension\n",
    "    if w < h:\n",
    "        image = imutils.resize(image, width=width,\n",
    "            inter=inter)\n",
    "        dH = int((image.shape[0] - height) / 2.0)\n",
    "\n",
    "    # otherwise, the height is smaller than the width so\n",
    "    # resize along the height and then update the deltas\n",
    "    # crop along the width\n",
    "    else:\n",
    "        image = imutils.resize(image, height=height,\n",
    "            inter=inter)\n",
    "        dW = int((image.shape[1] - width) / 2.0)\n",
    "\n",
    "    # now that our images have been resized, we need to\n",
    "    # re-grab the width and height, followed by performing\n",
    "    # the crop\n",
    "    (h, w) = image.shape[:2]\n",
    "    image = image[dH:h - dH, dW:w - dW]\n",
    "\n",
    "    # finally, resize the image to the provided spatial\n",
    "    # dimensions to ensure our output image is always a fixed\n",
    "    # size\n",
    "\n",
    "    image =  cv2.resize(image, (width, height),\n",
    "        interpolation=inter)\n",
    "    image_arr = img_to_array(image)\n",
    "    image_arr = image_arr/255.0\n",
    "    return img_to_array(image_arr)\n",
    "\n",
    "def selector(x):\n",
    "    \"\"\" Function to select the class\"\"\"\n",
    "    if x[0] > x[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_16_TL(input_shape,layers_to_skip=None,weights=None,include_top=True):\n",
    "    \"\"\" VGG 16 with Transfer Learning. Using Keras built in function\"\"\"\n",
    "    model = applications.VGG16(weights = weights, include_top=include_top, input_shape = input_shape)\n",
    "    if layers_to_skip:\n",
    "        if weights==None:\n",
    "            print(\"ERROR: You cannot have weights as none if layers_to_skip is non-zero\")\n",
    "        else:\n",
    "            for layer in model.layers[:layers_to_skip]:\n",
    "                layer.trainable = False\n",
    "            #Adding custom Layers \n",
    "            x = model.output\n",
    "            x = Flatten()(x)\n",
    "            x = Dense(4096, activation=\"relu\")(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "            x = Dense(4096, activation=\"relu\")(x)\n",
    "            x = Dropout(0.5)(x)\n",
    "    else:\n",
    "        x = model.output\n",
    "    \n",
    "    predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    adam_opt = Adam(lr=0.01)\n",
    "    rms_opt = RMSprop(lr=0.01)\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "    # creating the final model \n",
    "    model_final = Model(input = model.input, output = predictions)\n",
    "    model_final.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    return model_final\n",
    "\n",
    "def VGG_16(weights_path=None):\n",
    "    initializer = glorot_normal()\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),input_shape=(length,width,depth),\n",
    "                     activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, 3, 3, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu',kernel_initializer=initializer))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    adam_opt = Adam(lr=0.01)\n",
    "    rms_opt = RMSprop(lr=0.01)\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    #print(model.summary())\n",
    "    return model\n",
    "\n",
    "def CNN_FF():\n",
    "    \"\"\" CNN with Feed Forward NN \"\"\"\n",
    "    model_conv = Sequential()\n",
    "    model_conv.add(Conv2D(32, kernel_size=(5, 5), \n",
    "                                          input_shape=(length,width,depth),activation='relu'))\n",
    "    model_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_conv.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model_conv.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model_conv.add(Flatten())\n",
    "    model_conv.add(Dense(100))\n",
    "    model_conv.add(Dropout(0.1))\n",
    "    model_conv.add(Dense(num_classes, activation='softmax'))\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "    model_conv.compile(loss = 'binary_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "    #print(model_conv.summary())\n",
    "    return model_conv\n",
    "\n",
    "\n",
    "def save_model(model,vgg=True):\n",
    "    # saving model\n",
    "    json_model = model.to_json()\n",
    "    # Get today's date. We will use this as string for filename\n",
    "    now = datetime.datetime.now()\n",
    "    day = str(now)[:10]\n",
    "    if vgg:\n",
    "        arch_name = 'model_architecture_vgg_'+day+'35K_aug'+'.json'\n",
    "        model_weights = 'model_weights_vgg_'+day+'35K_aug'+'.h5'\n",
    "    else:\n",
    "        arch_name = 'model_architecture_s_cnn'+day+'.json'\n",
    "        model_weights = 'model_weights_s_cnn'+day+'.h5'\n",
    "        \n",
    "    open(arch_name, 'w').write(json_model)\n",
    "    # saving weights\n",
    "    model.save_weights(model_weights, overwrite=True)\n",
    "\n",
    "def load_model(model_arch,model_weights):\n",
    "    # loading model\n",
    "    model = model_from_json(open(model_arch).read())\n",
    "    model.load_weights(model_weights)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the csv data\n",
    "orig_label = pd.read_csv(\"./Retinal-Images/trainLabels.csv\")\n",
    "# Load the test csv data\n",
    "test_label = pd.read_csv(\"./Retinal-Images/retinopathy_solution.csv\")\n",
    "test_label.drop('Usage',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    35126\n",
       "level    35126\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    53576\n",
       "level    53576\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image\n",
       "level       \n",
       "0      25810\n",
       "1       2443\n",
       "2       5292\n",
       "3        873\n",
       "4        708"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_label.groupby(['level']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image\n",
       "level       \n",
       "0      39533\n",
       "1       3762\n",
       "2       7861\n",
       "3       1214\n",
       "4       1206"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.groupby(['level']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4_orig_df = orig_label[orig_label.level==4].sample(200)\n",
    "l3_orig_df = orig_label[orig_label.level==3].sample(500)\n",
    "l2_orig_df = orig_label[orig_label.level==2].sample(500)\n",
    "l1_orig_df = orig_label[orig_label.level==1].sample(500)\n",
    "l0_orig_df = orig_label[orig_label.level==0].sample(3300)\n",
    "rest_orig_df = pd.concat([orig_label, l4_orig_df,l3_orig_df,\n",
    "                          l2_orig_df,l1_orig_df,l0_orig_df]).drop_duplicates(keep=False)\n",
    "len(rest_orig_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4_test_df = test_label[test_label.level==4].sample(200)\n",
    "l3_test_df = test_label[test_label.level==3].sample(500)\n",
    "l2_test_df = test_label[test_label.level==2].sample(500)\n",
    "l1_test_df = test_label[test_label.level==1].sample(500)\n",
    "l0_test_df = test_label[test_label.level==0].sample(3300)\n",
    "rest_test_df = pd.concat([test_label, l4_test_df,l3_test_df,\n",
    "                          l2_test_df,l1_test_df,l0_test_df]).drop_duplicates(keep=False)\n",
    "len(rest_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataframes so that same sets can be loaded at a later point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4_orig_df.to_pickle(\"./l4_orig_df.pkl\")\n",
    "l3_orig_df.to_pickle(\"./l3_orig_df.pkl\")\n",
    "l2_orig_df.to_pickle(\"./l2_orig_df.pkl\")\n",
    "l2_orig_df.to_pickle(\"./l1_orig_df.pkl\")\n",
    "l0_orig_df.to_pickle(\"./l0_orig_df.pkl\")\n",
    "rest_orig_df.to_pickle(\"./rest_orig_df.pkl\")\n",
    "\n",
    "l4_test_df.to_pickle(\"./l4_test_df.pkl\")\n",
    "l3_test_df.to_pickle(\"./l3_test_df.pkl\")\n",
    "l2_test_df.to_pickle(\"./l2_test_df.pkl\")\n",
    "l2_test_df.to_pickle(\"./l1_test_df.pkl\")\n",
    "l0_test_df.to_pickle(\"./l0_test_df.pkl\")\n",
    "rest_test_df.to_pickle(\"./rest_test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = [l0_orig_df,l1_orig_df,l2_orig_df,l3_orig_df,l4_orig_df]\n",
    "test_list = [l0_test_df,l1_test_df,l2_test_df,l3_test_df,l4_test_df]\n",
    "train_list = [rest_orig_df,rest_test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels=list()\n",
    "test_labels.append(list(l0_test_df.level.values))\n",
    "test_labels.append(list(l1_test_df.level.values))\n",
    "test_labels.append(list(l2_test_df.level.values))\n",
    "test_labels.append(list(l3_test_df.level.values))\n",
    "test_labels.append(list(l4_test_df.level.values))\n",
    "test_labels = [item for sublist in test_labels for item in sublist]\n",
    "test_labels=np.asarray(test_labels)\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_list=list()\n",
    "test_image_list.append(list(l0_test_df.image.values))\n",
    "test_image_list.append(list(l1_test_df.image.values))\n",
    "test_image_list.append(list(l2_test_df.image.values))\n",
    "test_image_list.append(list(l3_test_df.image.values))\n",
    "test_image_list.append(list(l4_test_df.image.values))\n",
    "test_image_list = [item for sublist in test_image_list for item in sublist]\n",
    "test_image_list=np.asarray(test_image_list)\n",
    "test_image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels=list()\n",
    "val_labels.append(list(l0_orig_df.level.values))\n",
    "val_labels.append(list(l1_orig_df.level.values))\n",
    "val_labels.append(list(l2_orig_df.level.values))\n",
    "val_labels.append(list(l3_orig_df.level.values))\n",
    "val_labels.append(list(l4_orig_df.level.values))\n",
    "val_labels = [item for sublist in val_labels for item in sublist]\n",
    "val_labels=np.asarray(val_labels)\n",
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_list=list()\n",
    "val_image_list.append(list(l0_orig_df.image.values))\n",
    "val_image_list.append(list(l1_orig_df.image.values))\n",
    "val_image_list.append(list(l2_orig_df.image.values))\n",
    "val_image_list.append(list(l3_orig_df.image.values))\n",
    "val_image_list.append(list(l4_orig_df.image.values))\n",
    "val_image_list = [item for sublist in val_image_list for item in sublist]\n",
    "val_image_list=np.asarray(val_image_list)\n",
    "val_image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7704_left', '12406_right', '12224_right', ..., '28699_right',\n",
       "       '15243_right', '19751_right'], dtype='<U11')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[test_labels>0]=1\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy train images\n",
    "for i in range(2):\n",
    "    if i==0:\n",
    "        image_dir = os.getcwd()+'/Retinal-Images/train_resize_224/'\n",
    "        for j in range(len(rest_orig_df)):        \n",
    "            image_class = rest_orig_df.iloc[[j],[1]].values[0][0]\n",
    "            image_name = rest_orig_df.iloc[[j],[0]].values[0][0]\n",
    "            image_loc = image_dir+image_name+'.jpeg'\n",
    "            if image_class>0:\n",
    "                # Reset the class to 1\n",
    "                image_class_str=1\n",
    "                class_dir = 'class_'+str(image_class_str)\n",
    "                out_dir = os.getcwd()+'/Retinal-Images/train_new/'+class_dir+'/'\n",
    "                if image_class==3 or image_class==4:\n",
    "                    # Let us create 4 copies for same image\n",
    "                    copy_loc_1 = out_dir+image_name+'-1.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_1)\n",
    "                    copy_loc_2 = out_dir+image_name+'-2.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_2)\n",
    "                    copy_loc_3 = out_dir+image_name+'-3.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_3)\n",
    "                    copy_loc_4 = out_dir+image_name+'-4.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_4)\n",
    "                else:\n",
    "                    # For class 1 and 2 let us create 3 copies for same image\n",
    "                    copy_loc_1 = out_dir+image_name+'-1.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_1)\n",
    "                    copy_loc_2 = out_dir+image_name+'-2.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_2)\n",
    "                    copy_loc_3 = out_dir+image_name+'-3.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_3)\n",
    "            else:\n",
    "                class_dir = 'class_'+str(image_class)\n",
    "                out_dir = os.getcwd()+'/Retinal-Images/train_new/'+class_dir+'/'\n",
    "                copy_loc = out_dir+image_name+'.jpeg'\n",
    "                copyfile(image_loc,copy_loc)                \n",
    "    else:\n",
    "        image_dir = os.getcwd()+'/Retinal-Images/test_resize_224/'\n",
    "        for j in range(len(rest_test_df)):        \n",
    "            image_class = rest_test_df.iloc[[j],[1]].values[0][0]\n",
    "            image_name = rest_test_df.iloc[[j],[0]].values[0][0]\n",
    "            image_loc = image_dir+image_name+'.jpeg'\n",
    "            if image_class>0:\n",
    "                image_class_str=1\n",
    "                class_dir = 'class_'+str(image_class_str)\n",
    "                out_dir = os.getcwd()+'/Retinal-Images/train_new/'+class_dir+'/'\n",
    "                if image_class==3 or image_class==4:\n",
    "                    # Let us create 4 copies for same image\n",
    "                    copy_loc_1 = out_dir+image_name+'-1.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_1)\n",
    "                    copy_loc_2 = out_dir+image_name+'-2.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_2)\n",
    "                    copy_loc_3 = out_dir+image_name+'-3.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_3)\n",
    "                    copy_loc_4 = out_dir+image_name+'-4.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_4)\n",
    "                else:\n",
    "                    # For class 1 and 2 let us create 3 copies for same image\n",
    "                    copy_loc_1 = out_dir+image_name+'-1.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_1)\n",
    "                    copy_loc_2 = out_dir+image_name+'-2.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_2)\n",
    "                    copy_loc_3 = out_dir+image_name+'-3.jpeg'\n",
    "                    copyfile(image_loc,copy_loc_3)\n",
    "            else:\n",
    "                # No oversampling for class0\n",
    "                class_dir = 'class_'+str(image_class)\n",
    "                out_dir = os.getcwd()+'/Retinal-Images/train_new/'+class_dir+'/'\n",
    "                copy_loc = out_dir+image_name+'.jpeg'\n",
    "                copyfile(image_loc,copy_loc)                \n",
    "\n",
    "# Copy val images\n",
    "for df in val_list:\n",
    "    image_dir = os.getcwd()+'/Retinal-Images/train_resize_224/'\n",
    "    for j in range(len(df)):\n",
    "        image_class = df.iloc[[j],[1]].values[0][0]\n",
    "        if image_class>0:\n",
    "                image_class=1\n",
    "        image_name = df.iloc[[j],[0]].values[0][0]\n",
    "        image_loc = image_dir+image_name+'.jpeg'\n",
    "        class_dir = 'class_'+str(image_class)\n",
    "        out_dir = os.getcwd()+'/Retinal-Images/val/'+class_dir+'/'\n",
    "        copy_loc = out_dir+image_name+'.jpeg'\n",
    "        copyfile(image_loc,copy_loc)\n",
    "\n",
    "# Copy test images\n",
    "for df in test_list:\n",
    "    image_dir = os.getcwd()+'/Retinal-Images/test_resize_224/'\n",
    "    for j in range(len(df)):\n",
    "        image_name = df.iloc[[j],[0]].values[0][0]\n",
    "        image_loc = image_dir+image_name+'.jpeg'\n",
    "        out_dir = os.getcwd()+'/Retinal-Images/test_new/test/'\n",
    "        copy_loc = out_dir+image_name+'.jpeg'\n",
    "        copyfile(image_loc,copy_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy test images with 2 classes\n",
    "for df in test_list:\n",
    "    image_dir = os.getcwd()+'/Retinal-Images/test_resize_224/'\n",
    "    for j in range(len(df)):\n",
    "        image_class = df.iloc[[j],[1]].values[0][0]\n",
    "        if image_class>0:\n",
    "                image_class=1\n",
    "        image_name = df.iloc[[j],[0]].values[0][0]\n",
    "        image_loc = image_dir+image_name+'.jpeg'\n",
    "        class_dir = 'class_'+str(image_class)\n",
    "        out_dir = os.getcwd()+'/Retinal-Images/test_new/'+class_dir+'/'\n",
    "        copy_loc = out_dir+image_name+'.jpeg'\n",
    "        copyfile(image_loc,copy_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING (SKIP THIS PART IF YOU HAVE SAVED MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "length = 224\n",
    "width = 224\n",
    "depth = 3\n",
    "num_classes = 2\n",
    "input_shape = (224,224,3)\n",
    "\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 1 classes.\n",
      "Found 121221 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "         'Retinal-Images/test_new',\n",
    "         target_size=(224, 224),\n",
    "         batch_size=batch_size)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Retinal-Images/train_new',\n",
    "        target_size=(224,224),\n",
    "        classes = ['class_0','class_1'],\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "         'Retinal-Images/val',\n",
    "         target_size=(224, 224),\n",
    "         classes = ['class_0','class_1'],\n",
    "         batch_size=batch_size,\n",
    "         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "         'Retinal-Images/test_new',\n",
    "         target_size=(224, 224),\n",
    "         batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121221, 5000, 5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n_train = len(rest_orig_df) + len(rest_test_df)\n",
    "# Finding n_train with oversampling needs better coding. Hardcode for now\n",
    "n_train = 121221\n",
    "n_val = len(l0_orig_df)+len(l1_orig_df)+len(l2_orig_df)+len(l3_orig_df)+len(l4_orig_df)\n",
    "n_test = len(l0_test_df)+len(l1_test_df)+len(l2_test_df)+len(l3_test_df)+len(l4_test_df)\n",
    "n_train,n_val,n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "steps_per_epoch = int(n_train/batch_size)\n",
    "validation_steps = int(n_val/batch_size)\n",
    "test_steps = int(n_test/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_0': 0, 'class_1': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.03179102, 0.97010948])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "           'balanced',\n",
    "            np.unique(train_generator.classes), \n",
    "            train_generator.classes)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", kernel_initializer=<keras.ini...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 222, 222, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 222, 222, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 111, 111, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 113, 113, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 111, 111, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 55, 55, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 55, 55, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 57, 57, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 55, 55, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 57, 57, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 55, 55, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 27, 27, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 27, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 29, 29, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 27, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              75501568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 107,005,762\n",
      "Trainable params: 107,005,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=10, callbacks=[<keras.ca..., validation_data=<keras_pre..., validation_steps=250, steps_per_epoch=6061)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6061/6061 [==============================] - 2134s 352ms/step - loss: 0.6927 - acc: 0.5154 - val_loss: 0.7035 - val_acc: 0.3400\n",
      "Epoch 2/10\n",
      "6061/6061 [==============================] - 2114s 349ms/step - loss: 0.6925 - acc: 0.5155 - val_loss: 0.6997 - val_acc: 0.3462\n",
      "Epoch 3/10\n",
      "6061/6061 [==============================] - 2110s 348ms/step - loss: 0.6918 - acc: 0.5230 - val_loss: 0.7027 - val_acc: 0.4260\n",
      "Epoch 4/10\n",
      "6061/6061 [==============================] - 2110s 348ms/step - loss: 0.6904 - acc: 0.5352 - val_loss: 0.6633 - val_acc: 0.6398\n",
      "Epoch 5/10\n",
      "6061/6061 [==============================] - 2114s 349ms/step - loss: 0.6886 - acc: 0.5421 - val_loss: 0.7019 - val_acc: 0.4898\n",
      "Epoch 6/10\n",
      "6061/6061 [==============================] - 2106s 347ms/step - loss: 0.6875 - acc: 0.5479 - val_loss: 0.7032 - val_acc: 0.4906\n",
      "Epoch 7/10\n",
      "6061/6061 [==============================] - 2107s 348ms/step - loss: 0.6865 - acc: 0.5524 - val_loss: 0.7025 - val_acc: 0.4954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fd03f9668>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = VGG_16_TL(input_shape)\n",
    "model = VGG_16()\n",
    "print(model.summary())\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=validation_generator,\n",
    "        nb_epoch=30,steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIME FOR PREDICTION (JUMP TO NEXT SECTION IF YOU HAVE SAVED MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 11s 43ms/step\n",
      "TN: 977,FP: 2323, FN: 499, TP:1201\n"
     ]
    }
   ],
   "source": [
    "# NOTE : PREDICT GENERATOR IS NO GOOD AS IT DOESNT SEEM TO MAINTAIN SEQUENCE\n",
    "pred=model.predict_generator(test_generator,verbose=1,steps=test_steps)\n",
    "prediction_vgg = np.array([selector(xi) for xi in pred])\n",
    "cnf = confusion_matrix(test_labels, prediction_vgg)\n",
    "tn, fp, fn, tp = cnf.ravel()\n",
    "print(\"TN: {},FP: {}, FN: {}, TP:{}\".format(tn,fp,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42242655, 0.5775734 ],\n",
       "       [0.519796  , 0.48020405],\n",
       "       [0.42575514, 0.57424486],\n",
       "       ...,\n",
       "       [0.42642525, 0.5735748 ],\n",
       "       [0.52736354, 0.47263652],\n",
       "       [0.5564203 , 0.44357973]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f08dcd5f8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGfCAYAAAB8wYmvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG0JJREFUeJzt3Xm0JWV5L+Dfe07TzaQyyAwKAkZbrxoFxEs0KBEheoMrokJuEjTk9jLRoEhEUCOJEVFjNDEhgVY6URNBjRqRMIZRo0AzySAqDRKgbURlEkQUuu4fve0coQfE073rO/U8a9Vi769q7/qKRa/+8b5f1a6u6wIA0GcT454AAMDqCCwAQO8JLABA7wksAEDvCSwAQO8JLABA7wksAEDvCSwAQO8JLABA781a0yc4f8mpHqULY7DPcz8x7inAYN1304m1Ns+33hMOnLa/a9f23B8pFRYAoPfWeIUFAFizqmZ+/WHmXyEA0DwVFgBoXA2g/iCwAEDjtIQAAHpAhQUAGjeECovAAgCNq+rlo1Om1cyPZABA81RYAKB5M7/+ILAAQOOGsIZl5l8hANA8FRYAaNwQKiwCCwA0bghPup35VwgANE+FBQAapyUEAPTeEALLzL9CAKB5KiwA0LghVFgEFgBoXMVvCQEAjJ0KCwA0TksIAOi9IQSWmX+FAEDzVFgAoHFDqLAILADQvJkfWGb+FQIAzVNhAYDGaQkBAL03hMAy868QAGieCgsANK4GUH8QWACgcUNoCQksANC4Kj9+CAAwdiosANA4LSEAoPeGsOh25l8hANA8FRYAaJyWEADQe0MILDP/CgGA5qmwAEDjhrDoVmABgNZpCQEAjJ8KCwA0bgiLbgUWAGic3xICAOgBFRYAaJy7hACA3hvCGpaZf4UAQPNUWACgdQNYdCuwAEDrBtAvGcAlAgCtU2EBgNZpCQEAvTeAwKIlBAD0ngoLALRuAOUHgQUAGtdpCQEAjJ8KCwC0buYXWAQWAGjexMxPLFpCAEDvqbAAQOsGsOhWYAGA1s38vKIlBAA8MlW1XVWdW1Vfr6prquqNo/FNquqsqrpu9M+NR+NVVR+uqkVVdWVVPXvKdx00Ov66qjpodecWWACgdRM1fduqPZDksK7r5ibZPcnrq2pukiOSnN113c5Jzh69T5J9k+w82uYl+cdkWcBJclSS5ybZLclRPws5K73ER/PvBQDokarp21ah67olXdddNnr9wyTXJtkmyX5JPjY67GNJXj56vV+Sj3fLXJhko6raKslLkpzVdd3tXdfdkeSsJPus6twCCwDwC6uq7ZP8apKLkmzRdd2S0a5bk2wxer1NkpunfOyW0djKxldKYAGA1tX0bVU1r6oumbLNe9jpqjZM8tkkb+q67u6p+7qu65J0032J7hICgNZN44Pjuq6bn2T+yvZX1TpZFlb+teu6z42Gv1tVW3Vdt2TU8rltNL44yXZTPr7taGxxkj0fMn7equalwgIAPCJVVUlOSHJt13UfnLLr5CQ/u9PnoCRfmDL++6O7hXZPcteodXRGkr2rauPRYtu9R2MrpcICAK1be89h2SPJ7yW5qqquGI29Lcl7k3y6qg5O8t9JXjXad2qS30yyKMmPkrw2Sbquu72q/jLJwtFx7+q67vZVnVhgAYDGdWvpSbdd1305K49He63g+C7J61fyXQuSLHik59YSAgB6T4UFAFo3gF9rFlgAoHUzP69oCQEA/afCAgCtW0uLbsdJYAGA1g1gDYuWEADQeyosANC6mV9gEVgAoHkDWMOiJQQA9J4KCwC0bgAVFoEFAFo3gH7JAC4RAGidCgsAtE5LCADovZmfVwQWAGhd50m3AADjp8ICAK2zhoWZ7ux/Oz9fOuXCdOny/Jc+L7/xyl/P/L/4WG696bYkyX333Jf1Nlwv7zzhLbnorEtzxknnLP/s4huW5B3zD8t2O28zrulDM7bdapN89EN/nM03e1y6LlnwybNz7ILT887DXpmX7b1Lli5dmu/94O7MO+y4LPnuHTng5XvkzX/0W6lK7rnnxznk7Sfkqmtvypw56+Q/P/POzJ69TmbNmsznT70o7/7gv4378hi3mZ9XBJYhW3zDknzplAtz5HGHZtasyfzt4cfnGc+bm3lHHbT8mM/8wxey3gbrJkme++Ln5Lkvfk6S5JYbvpN/eMcCYQUeoQceXJoj3v0vueLqG7PhBuvmK//xnpz9pavyoeNPybv++jNJkj9+7Uty5Bt/O4e87YTcePNt2ftV78qdd92bvfd8Zo597//LC/b7s9x//0+zzwHvzr0/uj+zZk3mnM/+ec4894pcfPmiMV8hrFmrXcNSVU+pqrdW1YdH21ur6qlrY3KsWUtu+m52mPvEzFl3diZnTebJz9opl33pyuX7u67LJedekV33evbDPrvw7Muz64t+dW1OF5p262135oqrb0yS3HPvj/ONRYuz9Zab5If33Lf8mPXXXzdd1yVJLrz0utx5171JkosvX5Rtttpk+XH3/uj+JMk6syYza9bk8s8wYBM1fVtPrTKwVNVbk5yUZcWmi0dbJTmxqo5Y89NjTdpmh61y3ZU35J677s39P/5Jrr7w67njtjuX77/uyhvy2I03zBbbbvawzy489/Ls9qKHBxlg9Z6w7ePzrKdtn4Wjqsifv+VVue7Cv88BL98jfzmqtkz1mlfvmTPOvWL5+4mJyoWnHZObLj8+53z5qiy84vq1Nnd6qmr6tp5aXYXl4CS7dl333q7r/mW0vTfJbqN9K1RV86rqkqq65Iv/ctp0zpdptNUTt8g+B74of/OW4/Lhw4/Pdjttk4mJ//lPYuHZl62wunLD1/87s+fMzjZP2mptThdmhA3Wn5MTjz80b/mLjy+vrvz5X306O+/+hpz07/+V173mJT93/AueNzcHvfqFeccxJy4fW7q0y+77Hpmdnvv67PLMHTP3yduu1WuAcVhdYFmaZOsVjG812rdCXdfN77pul67rdvk/v7vvLzM/1rBfe+nuecf8w/KWD/9J1n/M+tliu2XVlAcfeDCXfenK7PrCh7d9Fp5zWXbbSzsIflGzZk3mxOMPzac+/1/5wukLH7b/U5//cl6+727L3z/9KU/IP75/Xl75hx/I7Xfe87Dj77r7Rzn/q1/P3ns+c43OmwbUNG49tbrA8qYkZ1fVaVU1f7SdnuTsJG9c89NjTbv7jh8mSX7w3Tty2QVXZre9li2qvfbSb2XLJ2yRjTff6OeOX7p0aS4972vWr8CjcNxfzcs3F30nH/7oqcvHdtx+y+WvX7b3LvnW9d9Jkmy39aY5af6hOfhNx2bRt29dfszjN3lMHvfY9ZMk685ZJ3s9/3/lm6PPMGADWMOyyruEuq47vaqenGUtoJ/dDrI4ycKu6x5c05NjzTvunf+Ue+/+USZnTeZ33vSKrP+Y9ZIkC8+5PLutIJRc97UbsvFmG2WzrR+/tqcKTfvfu/5K/u8rXpCrrr0pF552TJLkqPd/Kq959Z7Zecets3Rpl5sWfy+HHHlCkuTIN/52Ntl4w/zNu/8gybK7jH7tZW/PlptvnI988I8yOTmRiYnKZ0+5MKedffnYrgvWllrTq8vPX3Kq5eswBvs89xPjngIM1n03nbhWSxU7HvyZafu79voTXtnLMovnsABA47peRozp5beEAIDeU2EBgNb1eLHsdBFYAKB1PX7g23TREgIAek+FBQBapyUEAPTeAPolA7hEAKB1KiwA0LoBLLoVWACgdQNYw6IlBAD0ngoLADSu0xICAHpvAP2SAVwiANA6FRYAaN0AFt0KLADQugGsYdESAgB6T4UFAFqnJQQA9N7MzytaQgBA/6mwAEDjOi0hAKD3BhBYtIQAgN5TYQGA1g3gOSwCCwC0bgD9kgFcIgDQOhUWAGidlhAA0HvuEgIAGD8VFgBo3QAqLAILADSuG8AaFi0hAKD3VFgAoHUDKD8ILADQOi0hAIDxU2EBgNa5SwgA6L0BBBYtIQCg91RYAKB1M7/AIrAAQOs6LSEAgPFTYQGA1g3gOSwCCwC0bgAtIYEFAFo38/OKNSwAQP+psABA4yYGUH4QWACgcQNYc6slBAD0n8ACAI2rmr5t9eeqBVV1W1Vd/ZDxP6mqb1TVNVX1/injR1bVoqr6ZlW9ZMr4PqOxRVV1xOrOqyUEAI2rtdsT+uckf5/k41PO/8Ik+yV5Ztd191fV5qPxuUkOSPK0JFsn+c+qevLoY8cmeXGSW5IsrKqTu677+spOKrAAAI9Y13UXVNX2Dxn+oyTv7bru/tExt43G90ty0mj821W1KMluo32Luq67IUmq6qTRsSsNLFpCANC46WwJVdW8qrpkyjbvEUzhyUmeX1UXVdX5VbXraHybJDdPOe6W0djKxldKhQUAGjedHaGu6+Ynmf8LfmxWkk2S7J5k1ySfrqonTd+sBBYA4Jd3S5LPdV3XJbm4qpYmeXySxUm2m3LctqOxrGJ8hbSEAKBxNTF926P070lemCSjRbWzk3w/yclJDqiqOVW1Q5Kdk1ycZGGSnatqh6qanWULc09e1QlUWACgcWvzJqGqOjHJnkkeX1W3JDkqyYIkC0a3Ov8kyUGjass1VfXpLFtM+0CS13dd9+Doe96Q5Iwkk0kWdF13zarOK7AAAI9Y13UHrmTX767k+KOTHL2C8VOTnPpIzyuwAEDjJgbwaH6BBQAa57eEAAB6QIUFABo3hAqLwAIAjVvLvyU0FlpCAEDvqbAAQON+iQe+NUNgAYDGDaAjpCUEAPSfCgsANG4IFRaBBQAaN4TAoiUEAPSeCgsANM5vCQEAvaclBADQAyosANC4IVRYBBYAaFwNYBGLlhAA0HsqLADQOC0hAKD3hhBYtIQAgN5TYQGAxg2hwiKwAEDjBnCTkJYQANB/KiwA0DgtIQCg92oA/ZIBXCIA0DoVFgBonJYQANB7NYDEoiUEAPSeCgsANG4ABRaBBQBaN4TAoiUEAPTeGq+w/PpWO63pUwAr8ObP/eG4pwCsJUOosGgJAUDj/JYQAEAPqLAAQOOGUGERWACgcRPVjXsKa5zAAgCNG0KFxRoWAKD3VFgAoHFDqD4ILADQuCGsYRlCKAMAGqfCAgCNG8KiW4EFABo3hHbJEK4RAGicCgsANE5LCADovXKXEADA+KmwAEDjtIQAgN4bQrtkCNcIADROhQUAGjeER/MLLADQuCGsYdESAgB6T4UFABo3hOqDwAIAjdMSAgDoARUWAGicu4QAgN7TEgIA6AEVFgBo3BCqDwILADRuCGtYhhDKAIDGqbAAQOOGsOhWYAGAxg0hsGgJAQC9p8ICAI0bQvVBYAGAxrlLCACgB1RYAKBxQ1h0K7AAQOOG0C4ZwjUCAI1TYQGAxg2hJaTCAgCNq+qmbVv9uWpBVd1WVVdPGfurqvpGVV1ZVZ+vqo2m7DuyqhZV1Ter6iVTxvcZjS2qqiNWd16BBQD4Rfxzkn0eMnZWkqd3XfeMJN9KcmSSVNXcJAckedroM/9QVZNVNZnk2CT7Jpmb5MDRsSulJQQAjVubLaGu6y6oqu0fMnbmlLcXJtl/9Hq/JCd1XXd/km9X1aIku432Leq67oYkqaqTRsd+fWXnVWEBgMZNTOM2Df4gyWmj19skuXnKvltGYysbXymBBQBYrqrmVdUlU7Z5v8Bn357kgST/Ot3z0hICgMZN56P5u66bn2T+L/q5qnpNkpcl2avrup9NaHGS7aYctu1oLKsYXyEVFgBo3ERN3/ZoVNU+SQ5P8ltd1/1oyq6TkxxQVXOqaockOye5OMnCJDtX1Q5VNTvLFuaevKpzqLAAAI9YVZ2YZM8kj6+qW5IclWV3Bc1JclZVJcmFXde9ruu6a6rq01m2mPaBJK/vuu7B0fe8IckZSSaTLOi67ppVnVdgAYDGreW7hA5cwfAJqzj+6CRHr2D81CSnPtLzCiwA0LjJcU9gLbCGBQDoPRUWAGjcdN4l1FcCCwA0zo8fAgD0gAoLADRuCBUWgQUAGjc5gMCiJQQA9J4KCwA0TksIAOg9tzUDAL03hAqLNSwAQO+psABA44bwW0ICCwA0TksIAKAHVFgAoHHuEgIAes+TbgEAekCFBQAaN4RFtwILADRuCIFFSwgA6D0VFgBo3BAqLAILADRucgC3NWsJAQC9p8ICAI0bQvVBYAGAxg1hDcsQQhkA0DgVFgBo3BAqLAILADTOXUIAAD2gwgIAjdMSAgB6bwiBRUsIAOg9FRYAaNwQKiwCCwA0bnIAgUVLCADoPRUWAGjcxACewyKwAEDjhtAuGcI1AgCNU2EBgMa5SwgA6L0h3CUksJAHH3wwr3jFm7PFFpvk+OOPyle/+rW8//0L8tOfPpCnPW2nHH30IZk1azJ33XVP3va2v81NN92aOXPWyXve88Y8+clPHPf0oQmXzP9Ellx+VeY89jHZ+31/liS58pOfy5LLrsrErMlssMVm2WXe72X2BusnSb7xhdPz7fO/mpqoPOv3X5UtnzF3pd8DQ2ANC/n4x7+YHXfcNkmydOnSHHHE3+SDHzw8p5xybLbeerN8/vNnJ0mOO+7TeepTn5QvfvHv8r73HZqjj54/zmlDU574/N3za4e/4efGNn/6U/Li970jL37vO7LhlpvnGyefkSS5+5YlufnCS7P3+96R5x/+hlz+TyelW7p0pd8DE9VN29ZXAsvA3Xrr93PeeQuz//57J0nuvPOHWWedWdlhh22SJHvs8as588yvJEmuv/7m7L77M5IkO+64XRYvvi3f//4d45k4NGazp+6c2Rtu8HNjWz5jbiYmJ5Mkm+60Q+67/c4kyXcu/Vq22/05mVxnnWyw+eOz4Rab5fbrb1zp98BETd/WV486sFTVa6dzIozHe97zkbzlLa/NxMSy/xQ23vixefDBB3PVVdclSU4//b9y663fT5I85Sk7LA8vV175rXznO7fl1lt/MJ6Jwwxz4/lfyZbPXNb2ue+Ou7Lephsv37feJhstDzMwVL9MheUvpm0WjMW5516cTTZ5XJ7+9J2Wj1VVPvjBw3PMMR/N/vu/ORtssN7yMDNv3v754Q/vzX77HZJPfOKLeepTn5TJSUU6+GVd+++npSYn84Q9dhv3VGjUECosq1x0W1VXrmxXki1W8bl5SeYlyfHHvyvz5r36UU+QNeeyy67NOedcnAsuuDT33/+T3HPPj/Knf/rX+cAHDssnP/m+JMmXv3xZbrxxcZJkww3XzzHHvClJ0nVd9trrD7PddluObf4wE9x4/lez5PKr84K3vTFVy/62WG/jx+W+H/xPu/W+2+/MeptsNK4p0oAh/K/j6u4S2iLJS5I8dKFCJfnKyj7Udd38JKMVmd/q7wqegTvssINy2GEHJUkuuuiqLFjwuXzgA4flBz+4M5tuulF+8pOf5iMf+Wxe97pXJUnuvvuerLvunMyevU4+85kzs8suT8uGG64/zkuApt36tWvyzVPOyp5/dmhmzZm9fHyr5zwjFx/7T9n5N/fKj++4K/fcels22XH78U0UemB1geWUJBt2XXfFQ3dU1XlrZEaM3Uc/+rmcd97CLF3a5cAD983znvfMJMn119+SI474UJLKzjs/IUcffch4JwoNuejvF+R7134r9//wnvzHG96Wufu/NN84+cws/elPc8Exf5ck2XSn7fPsg38nj9t262z73GfnzMP/MjU5kWe95oDUqDW7ou/ZYc89xnlp9ED1uJUzXarr1nQBRIUFxuHtl9w87inAYB29y15rNUIs/N5/TNvftbtu9tJexp8htL0AgMZ50i0ANG4ILSGBBQAaN4R2yRCuEQBonAoLADSuevwbQNNFYAGAxg1gCYuWEADQfyosANA4dwkBAL03gLyiJQQA9J8KCwA0bmIAJRaBBQAaN4C8oiUEAPSfCgsANM5dQgBA7w0grwgsANC6IQQWa1gAgN5TYQGAxrmtGQDovQHkFS0hAKD/VFgAoHFV3binsMYJLADQOC0hAIAeUGEBgMYN4Um3KiwA0LiJadxWp6oOraprqurqqjqxqtatqh2q6qKqWlRVn6qq2aNj54zeLxrt3/6XuUYAgNWqqm2SHJJkl67rnp5kMskBSd6X5ENd1+2U5I4kB48+cnCSO0bjHxod96gILADQuKrp2x6BWUnWq6pZSdZPsiTJi5L822j/x5K8fPR6v9H7jPbvVfXoGlgCCwA0rqZxW5Wu6xYn+UCSm7IsqNyV5NIkd3Zd98DosFuSbDN6vU2Sm0effWB0/KaP5hoFFgBguaqaV1WXTNnmTdm3cZZVTXZIsnWSDZLsszbm5S4hAGjcdN4l1HXd/CTzV7L7N5J8u+u67y07b30uyR5JNqqqWaMqyrZJFo+OX5xkuyS3jFpIj0vyg0czLxUWAGjc2moJZVkraPeqWn+0FmWvJF9Pcm6S/UfHHJTkC6PXJ4/eZ7T/nK7rHtVjeQUWAOAR6bruoixbPHtZkquyLEfMT/LWJG+uqkVZtkblhNFHTkiy6Wj8zUmOeLTn1hICgMZNrMUHx3Vdd1SSox4yfEOS3VZw7I+TvHI6ziuwAEDjBvCgWy0hAKD/VFgAoHFVj2oda1MEFgBonJYQAEAPqLAAQOOm88FxfSWwAEDjBpBXtIQAgP5TYQGAxg2h+iCwAEDjhrCGZQihDABonAoLADRv5pdYBBYAaFwNILBoCQEAvafCAgCNq5r59QeBBQCapyUEADB2KiwA0LghLLoVWACgeTM/sGgJAQC9p8ICAI1zlxAA0AAtIQCAsVNhAYDGuUsIAOi9IQQWLSEAoPdUWACgeTO//iCwAEDjqrSEAADGToUFAJo38yssAgsANM5dQgAAPaDCAgDNm/n1B4EFABqnJQQA0AMqLADQuCE8h0VgAYDmCSwAQM/VAFZ4zPwrBACap8ICAM3TEgIAem4Ii261hACA3lNhAYDmzfwKi8ACAI1zlxAAQA+osABA87SEAICe8+OHAAA9oMICAI0bwnNYBBYAaN7Mb5jM/CsEAJqnwgIAjRvColuBBQCaN/MDi5YQANB7KiwA0Dh3CQEADZj5DZOZf4UAQPNUWACgcUO4S6i6rhv3HOixqprXdd38cc8DhsafPfh5WkKszrxxTwAGyp89mEJgAQB6T2ABAHpPYGF19NBhPPzZgyksugUAek+FBQDoPYGFFaqqfarqm1W1qKqOGPd8YCiqakFV3VZVV497LtAnAgsPU1WTSY5Nsm+SuUkOrKq5450VDMY/J9ln3JOAvhFYWJHdkizquu6Grut+kuSkJPuNeU4wCF3XXZDk9nHPA/pGYGFFtkly85T3t4zGAGAsBBYAoPcEFlZkcZLtprzfdjQGAGMhsLAiC5PsXFU7VNXsJAckOXnMcwJgwAQWHqbrugeSvCHJGUmuTfLpruuuGe+sYBiq6sQkX03yK1V1S1UdPO45QR940i0A0HsqLABA7wksAEDvCSwAQO8JLABA7wksAEDvCSwAQO8JLABA7wksAEDv/X9nk2JHNm0wvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cnf, index = [i for i in range(2)],\n",
    "                  columns = [i for i in range(2)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LOAD SAVED MODEL AND PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pavan/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/pavan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model_vgg = load_model('./best_model.json',\n",
    "                           './best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 213s 854ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model_vgg.predict_generator(test_generator,verbose=1,steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46719748, 0.5328025 ],\n",
       "       [0.5901194 , 0.40988055],\n",
       "       [0.5445768 , 0.45542318],\n",
       "       ...,\n",
       "       [0.54268855, 0.45731142],\n",
       "       [0.4684366 , 0.5315634 ],\n",
       "       [0.5667445 , 0.43325552]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 3026,FP: 274, FN: 1563, TP:137\n"
     ]
    }
   ],
   "source": [
    "prediction_vgg = np.array([selector(xi) for xi in pred])\n",
    "cnf = confusion_matrix(test_labels, prediction_vgg)\n",
    "tn,fp,fn,tp = cnf.ravel()\n",
    "print(\"TN: {},FP: {}, FN: {}, TP:{}\".format(tn,fp,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a98778860>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cnf, index = [i for i in range(2)],\n",
    "                  columns = [i for i in range(2)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 203s 813ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_val=model_vgg.evaluate_generator(validation_generator,verbose=1,steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.663347861289978"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6628066027164459"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 210s 841ms/step\n",
      "TN: 3026,FP: 274, FN: 1567, TP:133\n"
     ]
    }
   ],
   "source": [
    "# Predict test data\n",
    "pred_2=model_vgg.predict_generator(test_generator,verbose=1,steps=test_steps,workers=0)\n",
    "prediction_vgg = np.array([selector(xi) for xi in pred_2])\n",
    "cnf = confusion_matrix(test_labels, prediction_vgg)\n",
    "tn,fp,fn,tp = cnf.ravel()\n",
    "print(\"TN: {},FP: {}, FN: {}, TP:{}\".format(tn,fp,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 202s 808ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.663297012090683"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate test data\n",
    "test_acc=model_vgg.evaluate_generator(test_generator,verbose=1,steps=test_steps)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5442228\n",
      "4509\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(pred_2,columns=['DR','No_DR'])\n",
    "pred_df['True_Label'] = test_labels\n",
    "pred_df['Pred_Label'] = prediction_vgg\n",
    "\n",
    "# Extract True Positive\n",
    "pred_pos = pred_df[(pred_df.No_DR>=0.5) & (pred_df.True_Label==pred_df.Pred_Label)]\n",
    "print(np.max(pred_pos.No_DR))\n",
    "print(pred_pos.No_DR.idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testList = list(test_image_list)\n",
    "len(testList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    }
   ],
   "source": [
    "image_test = cv2.imread('./Retinal-Images/test_resize_224/10074_left.jpeg')\n",
    "image_test_pp_mod = np.expand_dims(image_test,0)\n",
    "pred_0 = model_vgg.predict_generator(\n",
    "    test_datagen.flow(image_test_pp_mod, batch_size=1),\n",
    "    steps=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55316824, 0.44683182]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction without using generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process each image one at a time\n",
    "image_class_list = list()\n",
    "for image in testList:\n",
    "    image_loc = './Retinal-Images/test_resize_224/' + image + '.jpeg'\n",
    "    image_test = cv2.imread(image_loc)\n",
    "    image_test_mod = preprocess(image_test)\n",
    "    image_test_pp_mod = np.expand_dims(image_test_mod,0)\n",
    "    image_class_proba = model_vgg.predict_proba(image_test_pp_mod).flatten()\n",
    "    image_class = selector(image_class_proba)\n",
    "    image_class_list.append(image_class)\n",
    "\n",
    "len(image_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_no_gen = np.asarray(image_class_list)\n",
    "pred_no_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 3195,FP: 105, FN: 1638, TP:62\n"
     ]
    }
   ],
   "source": [
    "cnf = confusion_matrix(test_labels, pred_no_gen)\n",
    "tn,fp,fn,tp = cnf.ravel()\n",
    "print(\"TN: {},FP: {}, FN: {}, TP:{}\".format(tn,fp,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a984d7a90>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cnf, index = [i for i in range(2)],\n",
    "                  columns = [i for i in range(2)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred_class = pd.DataFrame(test_image_list,columns=['Image'])\n",
    "df_pred_class['Actual'] = test_labels\n",
    "df_pred_class['Pred'] = image_class_list\n",
    "df_class_1 = df_pred_class[(df_pred_class.Pred==1)&(df_pred_class.Actual==df_pred_class.Pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>1909_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>34652_left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>23769_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>43285_left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>14804_left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>1415_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>18236_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>13917_left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>33487_left</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>41975_right</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image  Actual  Pred\n",
       "3310   1909_right       1     1\n",
       "3319   34652_left       1     1\n",
       "3322  23769_right       1     1\n",
       "3341   43285_left       1     1\n",
       "3562   14804_left       1     1\n",
       "3667   1415_right       1     1\n",
       "3757  18236_right       1     1\n",
       "3800   13917_left       1     1\n",
       "3814   33487_left       1     1\n",
       "3819  41975_right       1     1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7704_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12406_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12224_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11711_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31432_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image  Actual  Pred\n",
       "0    7704_left       0     0\n",
       "1  12406_right       0     0\n",
       "2  12224_right       0     0\n",
       "3  11711_right       0     0\n",
       "4   31432_left       0     0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0 = df_pred_class[(df_pred_class.Pred==0)&(df_pred_class.Actual==df_pred_class.Pred)]\n",
    "df_class_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image     62\n",
       "Actual    62\n",
       "Pred      62\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46853352, 0.5314664 ]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test = cv2.imread('./Retinal-Images/test_resize_224/41975_right.jpeg')\n",
    "image_test_pp = preprocess(image_test,scale=224)\n",
    "image_test_pp_mod = np.expand_dims(image_test_pp,0)\n",
    "image_class_proba = model_vgg.predict_proba(image_test_pp_mod)\n",
    "image_class_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 211s 845ms/step\n",
      "TN: 3013,FP: 287, FN: 1570, TP:130\n"
     ]
    }
   ],
   "source": [
    "# Predict validation data\n",
    "pred_val=model_vgg.predict_generator(validation_generator,verbose=1,steps=test_steps,workers=0)\n",
    "prediction_vgg = np.array([selector(xi) for xi in pred_val])\n",
    "cnf = confusion_matrix(val_labels, prediction_vgg)\n",
    "tn,fp,fn,tp = cnf.ravel()\n",
    "print(\"TN: {},FP: {}, FN: {}, TP:{}\".format(tn,fp,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 212s 848ms/step\n",
      "TN: 3013,FP: 287, FN: 1570, TP:130\n"
     ]
    }
   ],
   "source": [
    "pred_2=model_vgg.predict_generator(test_generator,verbose=1,steps=test_steps,workers=0)\n",
    "cnf = confusion_matrix(test_labels, prediction_vgg)\n",
    "tn,fp,fn,tp = cnf.ravel()\n",
    "print(\"TN: {},FP: {}, FN: {}, TP:{}\".format(tn,fp,fn,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0a986def60>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cm = pd.DataFrame(cnf, index = [i for i in range(2)],\n",
    "                  columns = [i for i in range(2)])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=\"YlGnBu\",fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
